{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "seed_text = \"bien y tu?\",\"muy mal\", \"Soy una tienda online\"\n",
    "\n",
    "encoded_input = tokenizer.encode(seed_text, return_tensors='pt')\n",
    "\n",
    "generated_text = model.generate(encoded_input)\n",
    "\n",
    "output_text = tokenizer.decode(generated_text[0], skip_special_tokens=True)\n",
    "\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot \n",
    "\n",
    "bot = telebot.TeleBot('5946891713:AAEqH_b0lL4d26_HfX73EvV1Ny6fsh1jhNM')\n",
    "@bot.message_handler(commands=['start', 'help'])\n",
    "\n",
    "def send_welcome(message):\n",
    "    bot.reply_to(message, \"Hola, en que te puedo ayudarte?\")\n",
    "\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def echo_all(message):\n",
    "    seed_text = message.text\n",
    "    encoded_input = tokenizer.encode(seed_text, return_tensors='pt')    \n",
    "    generated_text = model.generate(encoded_input)\n",
    "    output_text = tokenizer.decode(generated_text[0], skip_special_tokens=True)\n",
    "    bot.reply_to(message, output_text)\n",
    "\n",
    "bot.polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import telebot\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "# Inicializar el bot de Telegram\n",
    "bot = telebot.TeleBot('5946891713:AAEqH_b0lL4d26_HfX73EvV1Ny6fsh1jhNM')\n",
    "\n",
    "# Cargar el modelo BERT pre-entrenado\n",
    "model = transformers.BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "# Manejar mensajes de pregunta de Telegram\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def answer_question(message):\n",
    "    # Extraer la pregunta del mensaje\n",
    "    question = message.text\n",
    "    #extraer texto de un archivo de texto\n",
    "    with open('texto.txt', 'r') as file:\n",
    "        text = file.read().replace('\\n', '')\n",
    "\n",
    "    #el tokenizador acepta archivo mas largo de 512\n",
    "    if len(text) > 512:\n",
    "        text = text[-512:]\n",
    "\n",
    "    inputs = tokenizer.encode_plus(question, text, return_tensors='pt', add_special_tokens=True)\n",
    "    output = model(**inputs)\n",
    "\n",
    "    # Obtener la respuesta\n",
    "    answer_start_scores, answer_end_scores = output[:2]\n",
    "    answer_start = torch.argmax(answer_start_scores)\n",
    "    answer_end = torch.argmax(answer_end_scores) + 1\n",
    "    answer = tokenizer.decode(inputs['input_ids'][0][answer_start:answer_end])\n",
    "\n",
    "    #manejar errores de respuesta\n",
    "    if answer == '[CLS]':\n",
    "        answer = 'No entiendo tu pregunta'\n",
    "\n",
    "    #manejar problemas de respuesta\n",
    "    if answer == '[SEP]':\n",
    "        answer = 'No entiendo tu pregunta'\n",
    "    \n",
    "\n",
    "    # Enviar la respuesta al usuario\n",
    "    bot.reply_to(message, answer)\n",
    "\n",
    "    #guardar las preguntas en texto.txt\n",
    "    with open('texto.txt', 'a') as file:\n",
    "        file.write(question + ' ' + answer + ' ')\n",
    "    \n",
    "#el programa no se detiene nunca\n",
    "while True:\n",
    "    try:\n",
    "        bot.polling()\n",
    "    except Exception:\n",
    "        time.sleep(15)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot\n",
    "import transformers\n",
    "import torch\n",
    "import time \n",
    "\n",
    "# Inicializar el bot de Telegram\n",
    "bot = telebot.TeleBot('5946891713:AAEqH_b0lL4d26_HfX73EvV1Ny6fsh1jhNM')\n",
    "\n",
    "# Cargar el modelo BERT pre-entrenado\n",
    "model = transformers.BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad', max_length=10000)\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "# Manejar mensajes de pregunta de Telegram\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def answer_question(message):\n",
    "    # Extraer la pregunta del mensaje\n",
    "    question = message.text\n",
    "    #extraer texto de un archivo de texto\n",
    "    with open('texto.txt', 'r') as file:\n",
    "        text = file.read().replace('\\n', '')\n",
    "\n",
    "    #el tokenizador acepta archivo mas largo de 512\n",
    "    if len(text) > 512:\n",
    "        text = text[-512:]\n",
    "\n",
    "    inputs = tokenizer.encode_plus(question, text, return_tensors='pt', add_special_tokens=True)\n",
    "    output = model(**inputs)\n",
    "\n",
    "    # Obtener la respuesta\n",
    "    answer_start_scores, answer_end_scores = output[:2]\n",
    "    answer_start = torch.argmax(answer_start_scores)\n",
    "    answer_end = torch.argmax(answer_end_scores) + 1\n",
    "    answer = tokenizer.decode(inputs['input_ids'][0][answer_start:answer_end])\n",
    "    \n",
    "    # Enviar la respuesta al usuario\n",
    "    bot.reply_to(message, answer)\n",
    "\n",
    "    #guardar las preguntas en texto.txt\n",
    "    with open('texto.txt', 'a') as file:\n",
    "        file.write(question + ' ' + answer + ' ')\n",
    "\n",
    "#el programa no se detiene nunca\n",
    "while True:\n",
    "    try:\n",
    "        bot.polling()\n",
    "    except Exception:\n",
    "        time.sleep(15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
